33851171


查看Linux版本：
```
cat /etc/centos-release
```

查看CPU个数
cat /proc/cpuinfo | grep “processor” | wc -l

查看物理cpu个数：
cat /proc/cpuinfo | grep “physical id” | sort | uniq | wc -l

查看每个物理cpu的核数cores：
cat /proc/cpuinfo | grep “cpu cores”

如果所有物理cpu的cores个数加起来小于逻辑cpu的个数，则该cpu使用了超线程技术。查看每个物理cpu中逻辑cpu的个数：cat /proc/cpuinfo | grep “siblings”

查看内存使用情况

查看内存占用情况：free -m

## java jvm.options
```java
JAVA_OPTS="Xms=1024m Xmx=4096m -Dfile.encoding=utf-8"
```

## shell
# kill -9 worker3
```
ps -ef |grep worker3|awk '{print $2}'|xargs kill -9
```


## MySQL
# login
```bash
mysql -h 172.16.3.21 -P 31347 -u apim -p
```

# mysqldump
```bash
mysqldump -h172.16.3.21  -P31112 -uroot -pqwerasdf –-database epm > epm.sql
```

# mysql
```bash
mysql -h172.16.11.150 -P3306 -uroot -proot epm_boot.sql < /epm_boot.sql.sql

mysql -h172.16.11.150 -P3306 -uroot -proot -e "DROP DATABASE IF EXISTS portal"
```

# master-slave copy
```bash
show master/slave status;
change master to master_host='172.16.11.150', master_user='slave', master_password='slave', master_port=3301, master_log_file='mysql-bin.000001', master_log_pos= 2830, master_connect_retry=30;
start/stop slave
```

## mvn
# mvn install
mvn install:install-file -Dfile=./license-client-0.0.1-SNAPSHOT.jar -DgroupId=com.bonc.emcp -DartifactId=license-common -Dversion=0.0.1-SNAPSHOT -Dpackaging=jar

## RocketMQ
start broker
sh mqadmin  clusterList -n 10.168.12.207:9876
nohup sh mqbroker -c ../conf/2m-2s-sync/broker-a.properties autoCreateTopicEnable=true  &
nohup sh mqbroker -c ../conf/2m-2s-sync/broker-a-s.properties autoCreateTopicEnable=true &

nohup sh mqbroker -c ../conf/2m-2s-sync/broker-b.properties autoCreateTopicEnable=true &
nohup sh mqbroker -c ../conf/2m-2s-sync/broker-b-s.properties autoCreateTopicEnable=true  &

## kafka

# daemon start
bin/kafka-server-start.sh -daemon config/server.properties

# stop
/bin/kafka-server-stop.sh

# Related topics
# create topic
bin/kafka-topics.sh --create     --zookeeper localhost:2181 --replication-factor 2 --partitions 1 --topic test-topic

./kafka-consumer-groups.sh --bootstrap-server 24.43.105.10:9092 --group connect-cluster --topic iot_v1_property_up --reset-offsets --to-offset 1814221551 –execute

# query topics
bin/kafka-topics.sh --list       --zookeeper localhost:2181

# query topic-info
## all topics
bin/kafka-topics.sh --describe   --zookeeper localhost:2181 
## pointing topic
bin/kafka-topics.sh --describe   --zookeeper localhost:2181 --topic test-topic

# add partitions
bin/kafka-topics.sh --alter      --zookeeper localhost:2181 --topic httpmsg --partitions 2

# add replication
bin/kafka-reassign-partitions.sh --execute --zookeeper localhost:2181 --reassignment-json-file replica.json 
repliac.json
{
    "version": 1,
    "partitions": [
        {
            "topic": "sys_notice_response",
            "partition": 0,
            "replicas": [
                0,1    // brokerId

            ]
        }
    ]
}

# delete topic
1.如果kafka配置delete.topic.enable=true，那么可以直接删除topic，执行删除topic命令

bin/kafka-topics.sh --delete --zookeeper server01:2181  --topic test

2.如果kafka配置delete.topic.enable=false，删除操作如下：
bin/kafka-topics    --delete     --zookeeper localhost:2181 --topic test-topic

出现提示：
Topic test is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.

这里只是标记删除，并没有删除数据，同时也不能往这个topic写入数据

手动删除topic信息，具体操作如下：

# 1. 打开zkCli
zkCli.sh -server server01:2181

# 2. 删除zookeeper的topic相关信息

# 删除topic test的consumer group，如果有消费记录的话
rmr /consumers/test-group

rmr /config/topics/test
rmr /brokers/topics/test
rmr /admin/delete_topics/test

# 3. 在每台机器上，删除 topic 的 log 文件
rm -rf /hadoop/kafka/logs/test-*

# 4.重新启动kafka集群
bin/kafka-server-stop.sh
bin/kafka-server-start.sh -daemon config/server.properties

# query consoumer consume emergenyic
bin/kafka-consumer-groups.sh --group smart-toilet-consumer-group --describe --bootstrap-server 10.128.32.48:9090

# consumer message
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning

influxd restore -portable 

# kafka-connector add task


## RocketMQ

查看集群
```
sh mqadmin clusterList -n localhost:9876
```
查看消费者
```
sh mqadmin consumerStatus -n localhost:9876 -g api-manager-group
```



## influxdb 
# docker install
docker run -d -p 8086:8086 -p 8083:8083 -e INFLUXDB_ADMIN_ENABLED=true influxdb:1.7.6

# continuours query
CREATE CONTINUOUS QUERY st_sensor_cq_3m ON test BEGIN SELECT mean(sensorValue) INTO test.autogen.st_sensor_3m FROM test.autogen.st_sensor GROUP BY time(3m) END

# export Or import data
influx_inspect export -datadir "/data/influxdb/data" -waldir "/var/lib/influxdb/wal" -out "telemetry_vcdu_time" -database telemetry_vcdu_time -start 2019-07-21T08:00:01Z
influx_inspect export 
    -datadir "/data/influxdb/data" # 勿动，influxdb 默认的数据存储位置
    -waldir "/data/influxdb/wal"   # 勿动，influxdb 默认的数据交换位置
    -out "telemetry_vcdu_time"     # 导出数据文件的文件名
    -database telemetry_vcdu_time  # 指定要导出数据的数据库
    -start 2019-07-21T08:00:01Z    # 指定要导出的数据的起始时间
influx -import -path=telemetry_sat_time -precision=ns
influx 
    -import    # 无参，勿动
    -path=telemetry_sat_time # 指定导入数据的文件
    -precision=ns # 指定导入数据的时间精度

